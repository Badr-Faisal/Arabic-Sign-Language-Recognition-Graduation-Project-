{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input  # Preprocessing for ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import arabic_reshaper\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidi.algorithm import get_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 1. DATA LOADING & PREPROCESSING\n",
    "# ------------------------------\n",
    "\n",
    "# Set the dataset path (each subfolder should correspond to a label/letter)\n",
    "dataset_path = 'RGB ArSL dataset'  # Change this path to where your dataset is located\n",
    "IMG_SIZE = (224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(folder, img_size=IMG_SIZE):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for img_file in os.listdir(label_folder):\n",
    "                img_path = os.path.join(label_folder, img_file)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, img_size)\n",
    "                    images.append(img)\n",
    "                    labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels\n",
    "X, y = load_dataset(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to integers and then convert to one-hot vectors\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save label classes for later inference\n",
    "np.save('label_classes.npy', label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For display purposes, create a label map (first in English)\n",
    "label_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "print(f\"Original Label Map: {label_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from English label names to Arabic letters (customize as needed)\n",
    "english_to_arabic = {\n",
    "    'Ain': 'ع', 'Al': 'ال', 'Alef': 'ا', 'Beh': 'ب', 'Dad': 'ض', 'Dal': 'د',\n",
    "    'Feh': 'ف', 'Ghain': 'غ', 'Hah': 'ح', 'Heh': 'ه', 'Jeem': 'ج', 'Kaf': 'ك',\n",
    "    'Khah': 'خ', 'Laa': 'لا', 'Lam': 'ل',\n",
    "    'masafa': '<space>',\n",
    "    'mash': '<delete>',\n",
    "    'Meem': 'م', 'Noon': 'ن', 'Qaf': 'ق',\n",
    "    'Reh': 'ر', 'Sad': 'ص', 'Seen': 'س', 'Sheen': 'ش', 'Tah': 'ط', 'Teh': 'ت',\n",
    "    'Teh_Marbuta': 'ة', 'Thal': 'ذ', 'Theh': 'ث', 'Waw': 'و', 'Yeh': 'ي',\n",
    "    'Zah': 'ظ', 'Zain': 'ز'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the label map with Arabic letters based on the encoder's order\n",
    "label_map = {i: english_to_arabic.get(label, label) for i, label in enumerate(label_encoder.classes_)}\n",
    "print(f\"Arabic Label Map: {label_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images using ResNet50 function\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2. BUILD THE RESNET50-BASED MODEL\n",
    "# ------------------------------\n",
    "\n",
    "def create_resnet50_model(num_classes):\n",
    "    \"\"\"\n",
    "    Create a ResNet50-based model for Arabic Sign Language recognition.\n",
    "    Uses ImageNet pre-trained weights and custom top layers.\n",
    "    \"\"\"\n",
    "    # Load the ResNet50 base model without the top layers\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Initially freeze all layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01), use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu', use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using the number of classes from the label encoder\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_resnet50_model(num_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 3. DATA AUGMENTATION & MODEL TRAINING\n",
    "# ------------------------------\n",
    "\n",
    "# Set up data augmentation (rotations, shifts, shear, brightness, zoom, and horizontal flips)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute balanced class weights based on the training data\n",
    "y_train_int = np.argmax(y_train, axis=1)\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train_int), y=y_train_int)\n",
    "class_weights = dict(enumerate(class_weights_array))\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_asl_resnet50_model.keras', monitor='val_loss', save_best_only=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Phase 1: Train with Frozen Base -----------\n",
    "initial_epochs = 30\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=initial_epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Print out some of the base model layer names to inspect the ResNet50 structure\n",
    "base_model = model.layers[0]\n",
    "print(\"\\nResNet50 Base Model Layers:\")\n",
    "for idx, layer in enumerate(base_model.layers):\n",
    "    print(f\"Layer {idx}: {layer.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Phase 2: Fine-tuning -----------\n",
    "# Unfreeze the last ResNet50 block (conv5_block*) for fine-tuning.\n",
    "# This is often beneficial because the later layers capture higher-level features.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # Freeze all layers first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze layers that are part of the final convolutional block (\"conv5_block\")\n",
    "for layer in base_model.layers:\n",
    "    if \"conv5_block\" in layer.name:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fine_tune_epochs = 25\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save('asl_resnet50_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f'\\nValidation Accuracy: {val_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = 'RGB ArSL dataset'\n",
    "X_test, y_test = load_dataset(test_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_input(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_test_cat = to_categorical(y_test_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('asl_resnet50_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=2)\n",
    "print(f'Test Accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test_cat, axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model for real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('asl_resnet50_model.keras')\n",
    "label_classes = np.load('label_classes.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.classes_ = label_classes\n",
    "label_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "# Remap for inference:\n",
    "label_map = {i: english_to_arabic.get(label, label) for i, label in label_map.items()}\n",
    "print(\"Loaded Label Map for Inference:\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "captured_letters = []\n",
    "last_predicted_label = None\n",
    "frames_with_same_letter = 0\n",
    "cooldown_threshold = 7  # Frames to confirm prediction\n",
    "idle_timeout = 15       # Inactivity (sec) ends session\n",
    "last_activity_time = time.time()\n",
    "\n",
    "def format_arabic_text(letters):\n",
    "    return arabic_reshaper.reshape(''.join(letters))\n",
    "\n",
    "def draw_text(frame, text, position):\n",
    "    font_path = \"arial.ttf\"  # Ensure this font file is available\n",
    "    font = ImageFont.truetype(font_path, 35)\n",
    "    img_pil = Image.fromarray(frame)\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    draw.text(position, text, font=font, fill=(0, 255, 0))\n",
    "    return np.array(img_pil)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    roi_size = min(height, width) // 2\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    start_x = max(center_x - roi_size // 2, 0)\n",
    "    end_x = start_x + roi_size\n",
    "    start_y = max(center_y - roi_size // 2, 0)\n",
    "    end_y = start_y + roi_size\n",
    "    roi = frame[start_y:end_y, start_x:end_x]\n",
    "    cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "\n",
    "    roi_resized = cv2.resize(roi, IMG_SIZE)\n",
    "    roi_resized = preprocess_input(roi_resized)\n",
    "    roi_resized = np.expand_dims(roi_resized, axis=0)\n",
    "\n",
    "    prediction = model.predict(roi_resized, verbose=0)\n",
    "    confidence = np.max(prediction)\n",
    "    predicted_id = np.argmax(prediction)\n",
    "    predicted_label = label_map.get(predicted_id, '')\n",
    "\n",
    "    if confidence < 0.7:\n",
    "        predicted_label = None\n",
    "\n",
    "    if predicted_label == last_predicted_label:\n",
    "        frames_with_same_letter += 1\n",
    "    else:\n",
    "        frames_with_same_letter = 0\n",
    "\n",
    "    if frames_with_same_letter >= cooldown_threshold:\n",
    "        if predicted_label == '<space>':\n",
    "            captured_letters.append(' ')\n",
    "        elif predicted_label == '<delete>' and captured_letters:\n",
    "            captured_letters.pop()\n",
    "        elif predicted_label and predicted_label not in ['<space>', '<delete>']:\n",
    "            captured_letters.append(predicted_label)\n",
    "        last_predicted_label = None\n",
    "        frames_with_same_letter = 0\n",
    "        last_activity_time = time.time()\n",
    "    else:\n",
    "        last_predicted_label = predicted_label\n",
    "\n",
    "    if time.time() - last_activity_time > idle_timeout:\n",
    "        print(\"Final Sentence:\", format_arabic_text(captured_letters))\n",
    "        break\n",
    "\n",
    "    sentence = format_arabic_text(captured_letters)\n",
    "    frame = draw_text(frame, sentence, (10, 30))\n",
    "    cv2.imshow('ASL Recognition - ResNet50', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Final Sentence:\", format_arabic_text(captured_letters))\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
